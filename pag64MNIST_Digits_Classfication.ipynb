{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cot8X6iLRzAb"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZnTkiVfzRuVc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#comando usado para que los gráficos se muestren directamente dentro del notebook\n",
        "%matplotlib inline\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential # type: ignore\n",
        "from keras.layers import Dense, Dropout # type: ignore\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(0) #le fijamos un valor a la semilla para que a todos los alumnos nos den los mismos valores aleatorios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itkJl2JhSV3D"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-COGMFL7SMcr",
        "outputId": "1b502b42-f405-44ac-cd55-bf743c90a94b"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist  # type: ignore #importamos el dataset de imagenes\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()  #devuelve una tupla de numpy arrays\n",
        "#x_train: Una matriz que contiene las imágenes de entrenamiento.\n",
        "#y_train: es un vector que contiene las etiquetas correspondientes a cada imagen de entrenamiento\n",
        "#x_test: Una matriz que contiene las imágenes de prueba.\n",
        "#y_test: Un vector que contiene las etiquetas correspondientes a las imágenes de prueba.\n",
        "\n",
        "x_train.shape   #pedimos las dimensiones de la matriz.\n",
        "# eso devuelve (60000, 28, 28) -> es decir  devuelve 60000 matrices de 28x28\n",
        "# si hicieramos y_train.shape eso devuelve (60000,) es decir un vector con 60000 elemtos. En nuestro caso numeros etiquetando un 1, un 6,  un 4, etc.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pSoTVF3Sd34",
        "outputId": "abf3a241-8cc2-4957-9d6e-a9a3237a0488"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MN8ehUcSqqz"
      },
      "source": [
        "# Visualize Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "n2psUUkISllz",
        "outputId": "4d83b99d-6ea4-4d11-8092-54a282962358"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "f, ax = plt.subplots(1, num_classes, figsize=(20,20))\n",
        "#plt.subplots(): Esta función de Matplotlib crea una fila y un conjunto de subplots dentro de ella.\n",
        "#1, num_classes: Estos números indican que queremos crear una fila de subplots y que el número de columnas será igual a num_classes (en este caso, 10).\n",
        "#figsize=(20, 20): Este argumento establece el tamaño de la figura en pulgadas, en este caso, 20 pulgadas de ancho por 20 pulgadas de alto.\n",
        "\n",
        "\n",
        "for i in range(0, num_classes):\n",
        "  sample = x_train[y_train == i][0]   # ver explicacion en el cuadro de comentarios de debajo.\n",
        "  ax[i].imshow(sample, cmap='gray')\n",
        "  ax[i].set_title(\"Label: {}\".format(i), fontsize=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A7nOB_18t0-2"
      },
      "outputs": [],
      "source": [
        "# sample = x_train[y_train == i][0]    Aunque no hemos escrito explícitamente numpy en la instrucción y_train == i, NumPy está trabajando detrás de escena.\n",
        "# Supongamos que tengo 5 fotos de números. Los números son 6,4,9,2 y 3\n",
        "# En x_train tengo 5 matrices de 28x28 que indican el pixelado\n",
        "# En y_train tengo lo dicho  6,4,9,2,3 que etqietan con esevalor a que corresponde cada  foto\n",
        "# Si tengo la expresion\n",
        "# for i in range(2, 5):\n",
        "# minumeraco = x_train[y_train == i][0]\n",
        "# hara lo siguiente en la primera vuelta\n",
        "# y_train==2 contendra este vector booleano  [false, false, false, true, false] ya que en la instrucción y_train == i, NumPy está trabajando detrás de escena.\n",
        "# podemos decir que x_train[[False, False, False, True, False]] es equivalente a \"selecciona el elemento donde el vector booleano es True\". Es decir, el 4º elemento.\n",
        "# Al ponerle el [0] le decimos : “Y de todas las fotos que coinciden con un DOS seleccioname el primero”  es decir…. De todas mis fotos pillate la primera que sea un dos.\n",
        "\n",
        "# Añadimos una sexta foto de un 2:\n",
        "# •\tx_train: Ahora tenemos 6 matrices de 28x28 píxeles.\n",
        "# •\ty_train: Se convierte en [6, 4, 9, 2, 3, 2].\n",
        "# ¿Qué pasa si volvemos a ejecutar x_train[y_train == 2][0]?\n",
        "# En este caso, la expresión y_train == 2 generaría el siguiente vector booleano:\n",
        "# •\t[False, False, False, True, False, True]\n",
        "# Al tener dos valores True, significa que hay dos imágenes que corresponden al número 2. Sin embargo, al agregar [0] al final, estamos seleccionando específicamente la primera imagen que cumpla con la condición.\n",
        "# Por lo tanto, en este nuevo escenario:\n",
        "# •\tx_train[y_train == 2][0] seguiría devolviendo la primera imagen del número 2 que encuentres en x_train, que en este caso sería la misma que antes de agregar la nueva foto.\n",
        "# Si quisieras acceder a la segunda imagen del número 2, deberías usar un índice diferente:\n",
        "# •\tx_train[y_train == 2][1] te daría la segunda imagen del número 2.\n",
        "\n",
        "#ax[0] te daría acceso a la primera subgráfica, ax[1] a la segunda, y así sucesivamente.\n",
        "#imshow: Esta es una función de Matplotlib que se utiliza para mostrar una imagen.\n",
        "#Toma como entrada una matriz numérica que representa los valores de los píxeles de la imagen.\n",
        "#sample: Esta es la variable que contiene la matriz numérica con los datos de la imagen que quieres mostrar. Cada elemento de esta matriz corresponde a un píxel de la imagen.\n",
        "#cmap='gray': Este argumento especifica el mapa de colores que se utilizará para visualizar la imagen. En este caso, 'gray' indica que la imagen se mostrará en escala de grises, es decir, en tonos de blanco y negro.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-97b0iGYTBvv",
        "outputId": "1b31be17-8757-4388-c66a-9716f11a1ac2"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  print(y_train[i]) #escribimos en pantalla los primeros 10 valores de etiqueta de nuestras imagenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oJRS90sqTYyi"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)  #esto me saca el ONE_HOT DE LAS ETIQUETAS DE ENTRENAMIENTO\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)  #esto me saca el ONE_HOT DE LAS ETIQUETAS DE TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vXcJ3L0TzNx",
        "outputId": "63d81180-b4fe-41f5-b252-51e74171cf3f"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  print(y_train[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwQcpaBuUTe_"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yN6M-is5T0nu"
      },
      "outputs": [],
      "source": [
        "# Normalize Data  CON ESTO HACEMOS QUE TOME VALORES ENTRE 0 Y 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "#CADA PIXEL TOMA VALORES ENTRE 0 Y 255. AL DIVIDIR CADA VALOR ENTRE 255 HARA QUE LOS VALORES OSCILEN ENTRE 0 Y 1. EJ 255/255 =1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2kNxq2rUsoG",
        "outputId": "ed71a379-a234-4422-87ab-f01b109217ec"
      },
      "outputs": [],
      "source": [
        "# Reshape Data ESTO APLANA LA MATRIZ. EXPLICACION EN EL CUADRO DE COMENTARIOS DE DEBAJO\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bWQ5yxH-yPqt"
      },
      "outputs": [],
      "source": [
        "#x_train.reshape(): Esta función se utiliza para cambiar la forma de una matriz.\n",
        "# x_train.shape[0]: Esto toma el número de filas de la matriz x_train, que generalmente representa el número de imágenes.\n",
        "# -1: Este valor especial le indica a Python que calcule automáticamente el tamaño de la segunda dimensión para que todos los elementos de la matriz original queden aplanados en una sola fila.\n",
        "# print(x_train.shape) ESO VA A IMPRIMIR (60000, 784) que significa 60000 vectores de 784 elementos\n",
        "#para la imagen 1 podriamos tener esta ristra de 784 elementos  [0.0, 0.2, 1.0, 0.5, 0.0, 0.1, 0.0, 0.8, 0.3, 0.12, ..., 0.7, 0.9, 0.4]\n",
        "#tendremos 60000 ristras de 784 elementos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-K1km4JVQpe"
      },
      "source": [
        "# Create Model - Fully Connected Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "pOE4hD2HUxZt",
        "outputId": "c6a00b3e-e03b-4882-cc7f-372968b9b880"
      },
      "outputs": [],
      "source": [
        "model = Sequential()  #creamos un objeto de tipo modelo secuencial\n",
        "\n",
        "model.add(Dense(units=128, input_shape=(784,), activation='relu'))  #añadimos una capa de 128 neuronas con una funcion de activacion tipo relu\n",
        "#input_shape=(784,) le dice a la capa densa que espera recibir como entrada un vector plano (un array unidimensional) de 784 elementos.\n",
        "\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.25))  #para mejorar los calculos esta instruccion desactiva aleatoriamente un 25% de las neuronas de la capa anterior\n",
        "model.add(Dense(units=10, activation='softmax')) #esta capa de 10 neuronas se forma con una funcion activacion de tipo softmax\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #compilamos el modelo\n",
        "#categorical_crossentropy es una función de pérdida adecuada para problemas de clasificación multiclase\n",
        "#usaremos el optimizador ADAM, digamos que adam es quien regula las perillas que ajustan los pesos.\n",
        "#la métricas que se utilizará para evaluar el rendimiento del modelo en nuestro caso sera la precision (accuracy).\n",
        "#la precision corresponde con la proporción de predicciones correctas que hace el modelo.\n",
        "\n",
        "\n",
        "model.summary()  #esto muestra en pantall una descripcion de las capas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bk3ylbU1Ws4"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d75pU9l31S52",
        "outputId": "bb0462fd-ed6c-400e-f80b-9fbce72f5054"
      },
      "outputs": [],
      "source": [
        "#Definimos el tamaño del lote y las epocas para entrenar a nuestro modelo\n",
        "batch_size = 512\n",
        "epochs=10\n",
        "model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs)\n",
        "#como entradas toma a x_train como salidas toma a y_train  en lotes de 512 elementos y recorreremos 10 epocas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Wa4rvE1qMs"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4lONmsI1g9y",
        "outputId": "af72ba47-1104-4ce0-bbfe-c1f1d32427ec"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "#vamos a evaluar al modelo con datos de entrada y salida que nunca ha visto x_test y_test\n",
        "#esto nos devuelve una tupla con los datos de perdida y precision\n",
        "#por ejemplo nos puede dar un Test Loss= 0.06893616169691086 y una test_acc = 0.9789999723434448\n",
        "print(\"Test Loss: {}, Test Accuracy: {}\".format(test_loss, test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi7yXzCI10Kr",
        "outputId": "2e11cc55-3f06-4075-8b66-84e521aefdc3"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_test)   #esto genera predicciones para los datos de prueba que no conoce\n",
        "#devuelve un array DE PROBABILIDADES de ser un 0  o un 1 o un 2..... o un 9\n",
        "\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  #devolverá un array de los índices del valor máximo de probabilidad para cada numero.\n",
        "#Si por ejemplo uno de los numeros que devuelve fuera 2 significa\n",
        "#que el modelo predice que esa imagen corresponde al indice 2 es decir... corresponde al numero 2. indice 0 -> numero 0  indice 1->numero 1....indice 9 ->numero 9\n",
        "#axis=1 indica que queremos buscar el índice del valor máximo a lo largo de cada fila del array\n",
        "\n",
        "print(y_pred)\n",
        "print(y_pred_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "UxaVbpGo2ZOm",
        "outputId": "19171acd-fab0-4d7d-8072-b1a5af21dbef"
      },
      "outputs": [],
      "source": [
        "# Single Example\n",
        "random_idx = np.random.choice(len(x_test)) #esto selecciona una imagen al azar del conjunto de prueba.\n",
        "#Si random_idx = 27, entonces estaríamos seleccionando la imagen nº 28 de nuestro conjunto de prueba (ya que el primer índice es 0).\n",
        "\n",
        "x_sample = x_test[random_idx]  #en nuestro ejemplo x_sample = x_test[27] corresponde con la imagen 28 de pruebas en el ejemplo que hemos elegido\n",
        "\n",
        "y_true = np.argmax(y_test, axis=1) #esto devolvera un array con el mayor indice contenido en su correspondiente y_test\n",
        "#pero... si y_test ya eran etiquetas y no probabilidades ¿Por qué hacemos esto con y_test?\n",
        "#y_test generalmente contiene las etiquetas reales o verdaderas de nuestros datos de prueba. Estas etiquetas suelen estar codificadas\n",
        "# como one-hot encoded, es decir, cada fila representa una muestra y tiene un 1 en la columna correspondiente a su clase y 0 en el resto.\n",
        "# Encontrar el índice del valor máximo nos permite obtener la clase a la que pertenece cada muestra.\n",
        "#Por ejemplo, si una fila de y_test es [0, 1, 0], el índice del valor máximo es 1, lo que indica que la muestra pertenece a la clase 1.\n",
        "#EN RESUMEN y_true A LA HORA DE LA VERDAD VEMOS QUE CONTIENE LA POSICION DEL INDICE DEL VALOR CORRESPONDIENTE A LA IMAGEN\n",
        "\n",
        "y_sample_true = y_true[random_idx]\n",
        "#con esto sacamos el verdadero valor que hay en el indice indicado, En nuestro ejemplo indice 27\n",
        "\n",
        "y_sample_pred_class = y_pred_classes[random_idx]\n",
        "#Recordemos que y_pred_classes es un array de este estilo  [7 2 1 ... 4 5 6]...  en el indice 0 hay un 7 en nuestro ejemplo.\n",
        "#Este array contiene los valores que el modelo ha predicho en cada imagen de prueba\n",
        "#Por tanto en y_sample_pred_class almacenaremos el numero que habra predicho el modelo en el indice 27 segun nuestro ejemplo.\n",
        "\n",
        "plt.title(\"Predicted: {}, True: {}\".format(y_sample_pred_class, y_sample_true), fontsize=16)\n",
        "\n",
        "plt.imshow(x_sample.reshape(28, 28), cmap='gray') #x_sample es la matriz con la imagen la cual redimensionaremos en formato 28x28\n",
        "#toca redimensionarla porque algunos pasos mas atras para poder simplificar calculos habiamos aplanado la matriz pero para mostrarla\n",
        "#en pantalla necesitamos que no este aplanada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2kYQNGJ3aN5"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "77SFgjZ53KJ4",
        "outputId": "6db86844-422f-4ced-83ea-c3f5bb051200"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
        "#Esto crea una matriz de confusión, que es una tabla que compara las etiquetas reales de un conjunto de datos\n",
        "#(es decir, las clases a las que pertenecen realmente los datos) con las etiquetas predichas\n",
        "\n",
        "\n",
        "\n",
        "# Plot   PINTAMO LA MATRIZ EN PANTALLA\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "ax = sns.heatmap(confusion_mtx, annot=True, fmt='d', ax=ax, cmap=\"Blues\")\n",
        "ax.set_xlabel('Predicted Label')\n",
        "ax.set_ylabel('True Label')\n",
        "ax.set_title('Confusion Matrix');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-9WrS6w4TO0"
      },
      "source": [
        "# Investigate Some Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mTfbhmMW3xkU"
      },
      "outputs": [],
      "source": [
        "errors = (y_pred_classes - y_true != 0)\n",
        "#Supongamos que y_pred_classes=6  y_true=4  por tanto 6-4 es !=0 con lo cual eso da true.  errors = True\n",
        "#errors es True cuando la predicción del modelo es diferente de la clase real y False cuando la prediccion coincide con la real.\n",
        "#errors es un array de valores boleanos que compara prediccion vs realidad poniendo true  cuando difieren y false cuando coinciden\n",
        "\n",
        "y_pred_classes_errors = y_pred_classes[errors]\n",
        "#y_pred_classes[errors]: Aquí ocurre magia. Esta expresión se conoce como indexación booleana.\n",
        "#Lo que hace es seleccionar los elementos de y_pred_classes en las posiciones donde errors es True.\n",
        "#Es decir, está extrayendo las predicciones que fueron incorrectas.\n",
        "# Ejemplo: Imagina que tenemos:\n",
        "# y_pred_classes = [0, 1, 2, 1]\n",
        "# errors = [False, True, True, False]\n",
        "# Al ejecutar y_pred_classes_errors = y_pred_classes[errors], obtendríamos:\n",
        "# y_pred_classes_errors = [1, 2]\n",
        "# Esto nos indica que las predicciones 1 y 2 fueron incorrectas.\n",
        "\n",
        "\n",
        "y_pred_errors = y_pred[errors]\n",
        "#recordemos que y_pred es un array DE PROBABILIDADES de ser un 0  o un 1 o un 2..... o un 9\n",
        "#si al igual que antes le aplicamos la indexacion booleana lo que hace es seleccionar los elementos\n",
        "#de y_pred en las posiciones donde errors es True.\n",
        "#Es decir, está extrayendo las predicciones que fueron incorrectas.\n",
        "#Ejemplo de salida: Supongamos que y_pred_errors[:3] nos da la siguiente salida:\n",
        "# [[0.1 0.8 0.05 ... 0.02]\n",
        "#  [0.2 0.1 0.9 ... 0.01]\n",
        "#  [0.3 0.05 0.02 ... 0.6 ]]\n",
        "# Esto significa que:\n",
        "# Para la primera imagen errónea, el modelo tenía una probabilidad del 80% de que fuera un \"1\" (aunque en realidad era otro dígito).\n",
        "# Para la segunda imagen errónea, el modelo estaba casi seguro (90%) de que era un \"2\". (aunque en realidad era otro dígito).\n",
        "# Para la tercera imagen errónea, el modelo tenía un 60% de confianza en que era un \"9\". (aunque en realidad era otro dígito).\n",
        "\n",
        "\n",
        "y_true_errors = y_true[errors]\n",
        "# Se realiza una indexación booleana sobre y_true. Esto significa que se seleccionan los elementos\n",
        "#de y_true cuyas posiciones correspondientes en errors son True. En otras palabras, se están extrayendo\n",
        "#las etiquetas verdaderas de las muestras donde se cometieron errores.\n",
        "\n",
        "x_test_errors = x_test[errors]\n",
        "#En x_test[errors] Se realiza una indexación booleana sobre x_test. Esto significa que se seleccionan\n",
        "#los elementos de x_test cuyas posiciones correspondientes en errors son True. En otras palabras, se están extrayendo\n",
        "# las imagenes donde el modelo se equivocó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "w-IfVAiJ4os4"
      },
      "outputs": [],
      "source": [
        "y_pred_errors_probability = np.max(y_pred_errors, axis=1)\n",
        "#Supongamos que y_pred_errors nos diera la siguiente salida:\n",
        "# [[0.1 0.8 0.05 ... 0.02]\n",
        "#  [0.2 0.1 0.9 ... 0.01]\n",
        "#  [0.3 0.05 0.02 ... 0.6 ]]\n",
        "#al aplicarle np.max(y_pred_errors, axis=1)\n",
        "#Obtendríamos el siguiente array: [0.8, 0.9, 0.6] que corresponde con los valores maximos de cada fila.\n",
        "#En resumen obtenemos un nuevo array donde cada elemento representa la probabilidad más alta que el modelo asignó\n",
        "#a la clase que consideró más probable para cada imagen mal clasificada.\n",
        "\n",
        "true_probability_errors = np.diagonal(np.take(y_pred_errors, y_true_errors, axis=1))\n",
        "#np.take(y_pred_errors, y_true_errors, axis=1)) esto toma los errores de prediccion y los compara con las etiquetas de las imagenes reales\n",
        "#funciona asi np.take(listaoarraydelaqueextraerelementos,  indicesquequeremosextraer)  ->devuelve otro array con los elementos extraidos\n",
        "\n",
        "#np.diagonal: Esta función extrae la diagonal principal de una matriz.\n",
        "#funciona asi  np.diagonal(matrizdelaqueextraerladiagonal) -> devuelve un nuevo array con los elementos de la diagonal principal\n",
        "\n",
        "#en definitiva true_probability_errors = np.diagonal(np.take(y_pred_errors, y_true_errors, axis=1)) esto equivale a un  array con los elementos\n",
        "#de la diagonal principal de una matriz que esta formada por elementos extraidos de y_pred_errors habiendo extraido los elementos\n",
        "#que coincide con los indices que se expresan en  y_true_errors\n",
        "#ENTONCES UN VALOR POSIBLE PARA true_probability_errors PODRIA SER  [0.92, 0.85, 0.77, 0.91, 0.68,..., 0.54, 0.89, 0.72, 0.95, 0.61]\n",
        "\n",
        "\n",
        "diff_errors_pred_true = y_pred_errors_probability - true_probability_errors\n",
        "#calcula la diferencia entre las probabilidades predichas y las probabilidades verdaderas para cada muestra.\n",
        "#por ejemplo podria valer  [0.05, 0.12, -0.03, 0.09, -0.15,...,  0.21, 0.02, -0.11, 0.04, -0.07]\n",
        "#Valores negativos: Indican que el modelo subestimó la probabilidad de la clase correcta. Es decir, predijo una probabilidad menor\n",
        "#de lo que realmente debería haber sido.\n",
        "#Valores positivos: Indican que el modelo sobreestimó la probabilidad de la clase correcta. Es decir, predijo una probabilidad mayor\n",
        "#de lo que realmente debería haber sido.\n",
        "\n",
        "\n",
        "# Get list of indices of sorted differences  # Esto ordena el array y genera un nuevo array con los indices que corresponden a la ordenacion.\n",
        "sorted_idx_diff_errors = np.argsort(diff_errors_pred_true)\n",
        "#expliquemos esto con un ejemplo\n",
        "#suponiendo que diff_errors_pred_true = np.array([3, 1, 4, 1, 5, 9, 2]) ya sabemos que no vale eso... pero es un ejemplo...\n",
        "#sorted_idx_diff_errors = np.argsort(diff_errors_pred_true)\n",
        "#print(sorted_idx_diff_errors) -># Salida: [1 3 6 0 2 4 5]\n",
        "#vemos que el indice 1 y el indice 3 corresponde al elemento con valor 1\n",
        "#vemos que el indice 6 corresponde al elemento con valor 2\n",
        "#vemos que el indice 0 corresponde al elemento con valor 3\n",
        "#vemos que el indice 2 corresponde al elemento con valor 4\n",
        "#vemos que el indice 4 corresponde al elemento con valor 5\n",
        "#vemos que el indice 5 corresponde al elemento con valor 9\n",
        "\n",
        "\n",
        "top_idx_diff_errors = sorted_idx_diff_errors[-5:] # 5 last ones\n",
        "#esto hace un slicing de sorted_idx_diff_errors  para obtener los 5 ultimos elementos de dicho array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "99OZQyuI5H6h",
        "outputId": "1eb88236-226e-4758-a30b-bd2f181c42e1"
      },
      "outputs": [],
      "source": [
        "# Show Top Errors\n",
        "num = len(top_idx_diff_errors)  #num =5 segun la longitud de top_idx_diff_errors\n",
        "f, ax = plt.subplots(1, num, figsize=(30,30))  #creame 1 fila de subplots con 5 columnas (ya que num=5) con figuras de tamaño 30x30\n",
        "#f representa la figura completa (Figure object):\n",
        "#ax ax representa un array de objetos Axes: Cada Axes object es un subplot individual dentro de la figura.\n",
        "\n",
        "\n",
        "#RECORDEMOS\n",
        "# diff_errors_pred_true = y_pred_errors_probability - true_probability_errors   -> puede valer [0.05, 0.12, -0.03, 0.09, -0.15,...,  0.21, 0.02, -0.11, 0.04, -0.07]\n",
        "# sorted_idx_diff_errors = np.argsort(diff_errors_pred_true)  -> puede valer   [4, 8, 2, ..., 9, 0, 3, 7, 1, 5, 6]\n",
        "#POR TANTO\n",
        "# top_idx_diff_errors = sorted_idx_diff_errors[-5:]  -> puede valer  [ 3, 7, 1, 5, 6]\n",
        "\n",
        "for i in range(0, num):\n",
        "  idx = top_idx_diff_errors[i]   #En nuestro ejemplo en la posicion 0 vale 3  en la 1 vale 3 en la 2 vale 1.....\n",
        "\n",
        "  sample = x_test_errors[idx].reshape(28,28)\n",
        "  #recordemos que en x_test_errors se están extrayendo las imagenes donde el modelo se equivocó.\n",
        "  #se cogera esa imagen donde el modelo se equivoco que se encuentra en el indice almacenado en idx y la va a redimensionar a 28x28\n",
        "\n",
        "  y_t = y_true_errors[idx]\n",
        "  #recordemos que y_true_errors contiene las etiquetas verdaderas de las muestras donde se cometieron errores.\n",
        "  #se cogera el valor de esa etiqueta que se encuentra en el indice almacenado en idx\n",
        "\n",
        "  y_p = y_pred_classes_errors[idx]\n",
        "  #recordemos que y_pred_classes_errors contiene las predicciones que fueron incorrectas\n",
        "  #se cogera el valor de la prediccion que se encuentra en el indice almacenada en idx\n",
        "\n",
        "\n",
        "  ax[i].imshow(sample, cmap='gray')  #PARA CADA VUELTA DE i (es decir... para cada subplot) muestrame \"sample\" en escala de grises en pantalla\n",
        "  ax[i].set_title(\"Predicted label :{}\\nTrue label: {}\".format(y_p, y_t), fontsize=22)  #y ponle ese titulo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts_DcoFr5DnY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
